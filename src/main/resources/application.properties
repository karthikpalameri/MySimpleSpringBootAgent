spring.application.name=MySimpleSpringBootAgent

# Server Configuration
server.port=8080

# ========================================
# LangChain4j Ollama Configuration (DISABLED)
# ========================================
#langchain4j.ollama.chat-model.base-url=http://localhost:11434
#langchain4j.ollama.chat-model.model-name=llama3.2
#langchain4j.ollama.chat-model.temperature=0.3
#langchain4j.ollama.chat-model.timeout=300s
#langchain4j.ollama.chat-model.log-requests=true
#langchain4j.ollama.chat-model.log-responses=true

# ========================================
# LangChain4j OpenAI Configuration (for LM Studio)
# ========================================
langchain4j.open-ai.chat-model.base-url=http://localhost:1234/v1
langchain4j.open-ai.chat-model.api-key=not-needed
langchain4j.open-ai.chat-model.model-name=qwen/qwen3-vl-4b
langchain4j.open-ai.chat-model.temperature=0.7
langchain4j.open-ai.chat-model.max-tokens=2000
langchain4j.open-ai.chat-model.timeout=300s
langchain4j.open-ai.chat-model.log-requests=true
langchain4j.open-ai.chat-model.log-responses=true

# ========================================
# Logging Configuration
# ========================================
logging.level.com.simple.MySimpleSpringBootAgent=INFO
logging.level.dev.langchain4j=DEBUG
logging.level.dev.ai4j.openai4j=DEBUG

# ========================================
# Spring Boot Actuator (for monitoring)
# ========================================
management.endpoints.web.exposure.include=health,info,metrics
management.endpoint.health.show-details=always

